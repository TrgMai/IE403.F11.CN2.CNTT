"""
Thu·∫≠t to√°n Apriori - Khai ph√° lu·∫≠t k·∫øt h·ª£p (Association Rule Mining).
T√¨m t·∫≠p h·ª£p s·∫£n ph·∫©m th∆∞·ªùng ƒë∆∞·ª£c mua c√πng nhau.
T·ªëi ∆∞u: X·ª≠ l√Ω d·ªØ li·ªáu hi·ªáu qu·∫£ h∆°n, gi·∫£m memory usage.
"""
import pandas as pd
import numpy as np
import streamlit as st
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
from typing import Tuple, List
from src.config import APRIORI_CONFIG
import gc

class AprioriAlgorithm:
    """
    L·ªõp tri·ªÉn khai thu·∫≠t to√°n Apriori v·ªõi t·ªëi ∆∞u memory.
    
    Thu·∫≠t to√°n n√†y t√¨m Frequent Itemsets (t·∫≠p v·∫≠t ph·∫©m th∆∞·ªùng xuy√™n xu·∫•t hi·ªán)
    v√† Association Rules (lu·∫≠t k·∫øt h·ª£p) t·ª´ d·ªØ li·ªáu giao d·ªãch.
    """
    
    def __init__(self):
        """Kh·ªüi t·∫°o Apriori Algorithm."""
        self.frequent_itemsets = None
        self.rules = None
    
    def prepare_transaction_data(self, transaction_df: pd.DataFrame) -> List[List]:
        """
        Chu·∫©n b·ªã d·ªØ li·ªáu giao d·ªãch t·ª´ ƒë·ªãnh d·∫°ng DataFrame th√†nh danh s√°ch giao d·ªãch.
        
        Tham s·ªë:
        - transaction_df (pd.DataFrame): DataFrame ch·ª©a c·ªôt BASKET_ID v√† PRODUCT_ID
        
        Tr·∫£ v·ªÅ:
        - List[List]: Danh s√°ch c√°c giao d·ªãch, m·ªói giao d·ªãch l√† danh s√°ch PRODUCT_ID
        """
        # Nh√≥m c√°c s·∫£n ph·∫©m theo BASKET_ID (m·ªói gi·ªè h√†ng)
        transactions = transaction_df.groupby('BASKET_ID')['PRODUCT_ID'].apply(list).values.tolist()
        return transactions
    
    def run(self, transaction_df: pd.DataFrame, 
            min_support: float = 0.01, 
            min_confidence: float = 0.5) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Ch·∫°y thu·∫≠t to√°n Apriori v·ªõi t·ªëi ∆∞u memory.
        
        Tham s·ªë:
        - transaction_df (pd.DataFrame): D·ªØ li·ªáu giao d·ªãch
        - min_support (float): Ng∆∞·ª°ng h·ªó tr·ª£ t·ªëi thi·ªÉu (0-1). M·∫∑c ƒë·ªãnh 0.01 (1%).
        - min_confidence (float): Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y t·ªëi thi·ªÉu (0-1). M·∫∑c ƒë·ªãnh 0.5.
        
        Tr·∫£ v·ªÅ:
        - Tuple[pd.DataFrame, pd.DataFrame]: 
            - frequent_itemsets: B·∫£ng Frequent Itemsets
            - rules: B·∫£ng Association Rules
        """
        try:
            # Chu·∫©n b·ªã d·ªØ li·ªáu giao d·ªãch
            transactions = self.prepare_transaction_data(transaction_df)
            
            if not transactions:
                st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu giao d·ªãch ƒë·ªÉ x·ª≠ l√Ω.")
                return pd.DataFrame(), pd.DataFrame()
            
            st.info(f"üìä ƒêang x·ª≠ l√Ω {len(transactions):,} giao d·ªãch...")
            
            # Chuy·ªÉn ƒë·ªïi danh s√°ch giao d·ªãch th√†nh one-hot encoded DataFrame
            # S·ª≠ d·ª•ng sparse matrix ƒë·ªÉ ti·∫øt ki·ªám memory
            te = TransactionEncoder()
            te_ary = te.fit(transactions).transform(transactions)
            df_encoded = pd.DataFrame(te_ary, columns=te.columns_)
            
            # X√≥a transactions t·ª´ memory
            del transactions
            gc.collect()
            
            st.info(f"‚úÖ ƒê√£ load {df_encoded.shape[0]:,} giao d·ªãch, {df_encoded.shape[1]} s·∫£n ph·∫©m")
            st.info(f"‚öôÔ∏è T√¨m Frequent Itemsets v·ªõi min_support={min_support:.2%}...")
            
            # T√¨m Frequent Itemsets
            self.frequent_itemsets = apriori(df_encoded, 
                                              min_support=min_support, 
                                              use_colnames=True,
                                              max_len=3)  # Gi·ªõi h·∫°n ƒë·ªô d√†i itemset
            
            # X√≥a df_encoded t·ª´ memory
            del df_encoded
            gc.collect()
            
            if len(self.frequent_itemsets) == 0:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Frequent Itemsets v·ªõi min_support={min_support:.2%}")
                st.info("üí° G·ª£i √Ω: H√£y gi·∫£m min_support ho·∫∑c tƒÉng sample_size")
                return self.frequent_itemsets, pd.DataFrame()
            
            st.success(f"‚úÖ T√¨m th·∫•y {len(self.frequent_itemsets)} Frequent Itemsets")
            st.info(f"‚öôÔ∏è T√¨m Association Rules v·ªõi min_confidence={min_confidence:.1%}...")
            
            # T√¨m Association Rules
            if len(self.frequent_itemsets) > 1:
                self.rules = association_rules(self.frequent_itemsets, 
                                                metric='confidence', 
                                                min_threshold=min_confidence)
            else:
                self.rules = pd.DataFrame()
            
            # Th√™m c·ªôt h·ªØu √≠ch kh√°c
            if len(self.rules) > 0:
                self.rules['antecedent_str'] = self.rules['antecedents'].apply(
                    lambda x: ', '.join(str(i) for i in list(x))
                )
                self.rules['consequent_str'] = self.rules['consequents'].apply(
                    lambda x: ', '.join(str(i) for i in list(x))
                )
                self.rules = self.rules.sort_values('confidence', ascending=False)
                st.success(f"‚úÖ T√¨m th·∫•y {len(self.rules)} Association Rules")
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Association Rules")
            
            return self.frequent_itemsets, self.rules
        
        except MemoryError as e:
            st.error(f"‚ùå L·ªói Memory: D·ªØ li·ªáu qu√° l·ªõn!")
            st.warning("""
            **Gi·∫£i ph√°p:**
            - ‚¨áÔ∏è Gi·∫£m Sample Size trong C·∫•u h√¨nh (‚öôÔ∏è Config)
            - ‚¨ÜÔ∏è TƒÉng Min Support ƒë·ªÉ gi·∫£m itemsets
            - üíæ ƒê√≥ng c√°c tab/·ª©ng d·ª•ng kh√°c ƒë·ªÉ gi·∫£i ph√≥ng RAM
            """)
            return pd.DataFrame(), pd.DataFrame()
        
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ch·∫°y Apriori: {str(e)}")
            return pd.DataFrame(), pd.DataFrame()
    
    def get_recommendations(self, product_id: int, rules_df: pd.DataFrame) -> List[int]:
        """
        G·ª£i √Ω c√°c s·∫£n ph·∫©m li√™n quan d·ª±a tr√™n lu·∫≠t k·∫øt h·ª£p.
        
        Tham s·ªë:
        - product_id (int): ID s·∫£n ph·∫©m c·∫ßn t√¨m g·ª£i √Ω
        - rules_df (pd.DataFrame): B·∫£ng lu·∫≠t k·∫øt h·ª£p
        
        Tr·∫£ v·ªÅ:
        - List[int]: Danh s√°ch ID s·∫£n ph·∫©m ƒë∆∞·ª£c g·ª£i √Ω
        """
        recommendations = []
        
        for _, row in rules_df.iterrows():
            # antecedents v√† consequents l√† frozensets
            antecedents_set = row['antecedents']
            consequents_set = row['consequents']
            
            # Ki·ªÉm tra n·∫øu product_id n·∫±m trong antecedents
            # Chuy·ªÉn antecedents_set th√†nh list ƒë·ªÉ ki·ªÉm tra
            if product_id in antecedents_set:
                # Th√™m c√°c s·∫£n ph·∫©m trong consequents
                recommendations.extend(list(consequents_set))
        
        # N·∫øu kh√¥ng t√¨m th·∫•y product_id trong antecedents, 
        # th·ª≠ t√¨m trong consequents (s·∫£n ph·∫©m ƒë∆∞·ª£c mua c√πng)
        if not recommendations:
            for _, row in rules_df.iterrows():
                consequents_set = row['consequents']
                if product_id in consequents_set:
                    # Th√™m c√°c s·∫£n ph·∫©m trong antecedents
                    recommendations.extend(list(row['antecedents']))
        
        return list(set(recommendations))  # Lo·∫°i b·ªè tr√πng l·∫∑p

    
    def get_recommendations(self, product_id: int, rules_df: pd.DataFrame) -> List[int]:
        """
        G·ª£i √Ω c√°c s·∫£n ph·∫©m li√™n quan d·ª±a tr√™n lu·∫≠t k·∫øt h·ª£p.
        
        Tham s·ªë:
        - product_id (int): ID s·∫£n ph·∫©m c·∫ßn t√¨m g·ª£i √Ω
        - rules_df (pd.DataFrame): B·∫£ng lu·∫≠t k·∫øt h·ª£p
        
        Tr·∫£ v·ªÅ:
        - List[int]: Danh s√°ch ID s·∫£n ph·∫©m ƒë∆∞·ª£c g·ª£i √Ω
        """
        recommendations = []
        
        for _, row in rules_df.iterrows():
            # antecedents v√† consequents l√† frozensets
            antecedents_set = row['antecedents']
            consequents_set = row['consequents']
            
            # Ki·ªÉm tra n·∫øu product_id n·∫±m trong antecedents
            # Chuy·ªÉn antecedents_set th√†nh list ƒë·ªÉ ki·ªÉm tra
            if product_id in antecedents_set:
                # Th√™m c√°c s·∫£n ph·∫©m trong consequents
                recommendations.extend(list(consequents_set))
        
        # N·∫øu kh√¥ng t√¨m th·∫•y product_id trong antecedents, 
        # th·ª≠ t√¨m trong consequents (s·∫£n ph·∫©m ƒë∆∞·ª£c mua c√πng)
        if not recommendations:
            for _, row in rules_df.iterrows():
                consequents_set = row['consequents']
                if product_id in consequents_set:
                    # Th√™m c√°c s·∫£n ph·∫©m trong antecedents
                    recommendations.extend(list(row['antecedents']))
        
        return list(set(recommendations))  # Lo·∫°i b·ªè tr√πng l·∫∑p
